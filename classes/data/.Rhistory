# Setting my root directory to where I have my /data folder etc. (easier for me, but personalise to your own way of working)
knitr::opts_knit$set(root.dir = "/Users/aisroy/Desktop/UNI/BSc CogSci - 2nd Sem/Methods 2/github repos/methods2_resources/classes/data")
knitr::opts_chunk$set(echo = TRUE)
# Setting my root directory to where I have my /data folder etc. (easier for me, but personalise to your own way of working)
knitr::opts_knit$set(root.dir = "/Users/aisro/Desktop/UNI/BSc CogSci - 2nd Sem/Methods 2/github repos/methods2_resources/classes/data")
# Make sure this guy is installed/updated (if you've already got rstanarm installed, you just need to load it in using either library() or p_load() as below)
#install.packages("rstanarm")
#library(rstanarm)
#remove.packages("htmltools")
#packageVersion("htmltools") # do not look back. just move on. be happy it's there.
#install.packages("htmltools", version = "0.5.7")
#stan_glm(mpg ~ wt + cyl, data = mtcars) # testing line
# Load the rest
library(pacman)
pacman::p_load(tidyverse,
ggpubr,
ggplot2,
stringr,
rstanarm) # this time I'm just giving you the code
# Load data
hibbs <- read.table("ElectionsEconomy/data/hibbs.dat", header = TRUE)
knitr::opts_chunk$set(echo = TRUE)
# Setting my root directory to where I have my /data folder etc. (easier for me, but personalise to your own way of working)
knitr::opts_knit$set(root.dir = "/Users/aisro/Desktop/UNI/BSc CogSci - 2nd Sem/Methods 2/github repos/methods2_resources/classes/data")
# Load data
hibbs <- read.table("ElectionsEconomy/data/hibbs.dat", header = TRUE)
# Make scatterplot
plot(hibbs$growth, hibbs$vote, xlab="Average recent growth in personal income",
ylab="Incumbent party's vote share")
# Estimate regression y = a + bx + error
M1 <- stan_glm(vote ~ growth, data=hibbs)
# Add a fitted line to the graph
abline(coef(M1), col="violet") # needs to be run with the plot() code above - running the whole chunk is the easiest way
# Display the fitted model
print(M1)
View(hibbs)
#set.seed(1998) # setting a seed (in the best year ever??) - this way, even though it's random, you'll get reproducible results next time you run this with this seed --- im sorry
set.seed(2005)
# rnorm() works like: my_simulated_data <- rnorm(n, mean, sd) - now you go!
# your code here
simData <- rnorm(2005,4.5,1)
simDataPlot <- simData %>%
ggplot(aes(x = ""))+
geom_histogram()+
labs(x = "number"
y = "frequency",
simDataPlot <- simData %>%
ggplot(aes(x = ""))+
geom_histogram()+
labs(x = "number",
y = "frequency",
title = Simulated Data)
simDataPlot <- simData %>%
ggplot(aes(x = ""))+
geom_histogram()+
labs(x = "number",
y = "frequency",
title = "Simulated Data")
simDataPlot <- simData %>%
ggplot(aes(x = simData, y = x))+
geom_histogram(binwidth = 0.5, fill = "skyblue", color = "black")+
labs(x = "number",
y = "frequency",
title = "Simulated Data")
simData_df <- data.frame(x = simData)
View(simData_df)
simDataPlot <- simData_df %>%
ggplot(aes(x = simData, y = x))+
geom_histogram(binwidth = 0.5, fill = "skyblue", color = "black")+
labs(x = "number",
y = "frequency",
title = "Simulated Data")
simDataPlot
simDataPlot <- simData_df %>%
ggplot(aes(x = x))+
geom_histogram(binwidth = 0.5, fill = "skyblue", color = "black")+
labs(x = "number",
y = "frequency",
title = "Simulated Data")
simDataPlot <- simData_df %>%
ggplot(aes(x = x))+
geom_histogram(binwidth = 0.5, fill = "skyblue", color = "black")+
labs(x = "number",
y = "frequency",
title = "Simulated Data")
simDataPlot
simData_histo <- simData_df %>%
ggplot(aes(x = x))+
geom_histogram(binwidth = 0.5, fill = "skyblue", color = "black")+
labs(x = "number",
y = "frequency",
title = "Simulated Data")
simDatahisto
simData_histo
simData_summ <- simData_df %>%
summarise(mean(x)+
sd(x))
View(simData_summ)
simData_summ <- simData_df %>%
summarise(mean(x) %>%
sd(x))
simData_summ <- simData_df %>%
summarise(mean(x),
sd(x))
simData_summ
datData <- rnorm(3006, mean = 709, sd = 3)
datData_df <- data.frame(datData)
View(datData_df)
datData_df <- data.frame(x = datData)
set.seed(2984)
set.seed(2984)
datData <- rnorm(3006, mean = 709, sd = 3)
datData_df <- data.frame(x = datData) # vector to df
set.seed(607)
x <- 1:100 #IV
y <- 2 * x + rnorm(379, mean = 173, sd = 3) #DV + noise
datData_df <- data.frame(x = x, y = y) # vector to df
set.seed(607)
x <- 1:100 #IV
y <- 2 * x + rnorm(100, mean = 39, sd = 3) #DV + noise
datData_df <- data.frame(x = x, y = y) # vector to df
View(datData_df)
datData_model <- lm(y ~ x, data = data)
datData_model <- lm(y ~ x, data = datData_df)
summary(datData_model)
datData_plot <- datData_df %>%
ggplot(aes(x = x, y = y)) +
geom_point() +
geom_smooth(method = "lm") +
labs(x = "x",
y = "y",
title = "datData Scatter Plot w/ Regression Line")
datData_plot
newData <- data.frame(x = "x", y = "y", sd = 3.9)
View(datData_df)
newData_summ <- newData_df %>%
summarise(mean(y),
sd(y))
x <- 1:100
y <- 30 + 10 * x
newData_df <- data.frame(x = "x", y = "y", sd = 3.9)
newData_summ <- newData_df %>%
summarise(mean(y),
sd(y))
newData_summ <- newData_df %>%
summarise(mean("y"),
sd("y"))
newData_summ <- newData_df %>%
summarise(sd("y"))
newData_summ <- newData_df %>%
summarise(sd(y))
x <- 1:100
y <- 30 + 10 * x
newData_df <- data.frame(x = x, y = y, sd = 3.9)
newData_summ <- newData_df %>%
summarise(sd(y))
newData_summ
newData_summ <- newData_df %>%
summarise(sd(x))
newData_summ
x <- 1:100
y <- 30 + 10 * x
newData_df <- data.frame(x = x, y = y, sd = 3.9)
newData_summ <- newData_df %>%
summarise(sd(y))
newData_summ
newData_df <- data.frame(x = x, y = y, sd = 3.9)
newData_summ <- newData_df %>%
summarise(sd(y))
newData_summ
newData_summ <- newData_df %>%
summarise(sd())
newData_summ <- newData_df %>%
summarise(sd(x))
newData_summ
sd_x <- newData_df %>%
sd(x)
sd_x <- newData_df %>%
sd("x")
# playing around with some things.. didn't work sooooo it's hashed out, but here to keep track of what I was doing
### x <- 1:100
### y <- 30 + 10 * x
### newData_df <- data.frame(x = x, y = y, sd = 3.9)
### newData_summ <- newData_df %>%
### summarise(sd(x))
### newData_summ
# - - - - -
#### 1) First, define the regression model parameters (intercept, slope, error) (hint: just make variables called 'intercept' and so on and define the number)
newData_int <- 30
newData_slope <- 10
newData_err <- 3.9
#### 3) Generate X values in the specified range using seq()
x <- 1:100
#### 4) Calculate y values based on the given regression and your newly created x-values without the error term, which gives you the y get the perfect fit line
y <- 30 + 10x
y <- 30 + 10 * x
# playing around with some things.. didn't work sooooo it's hashed out, but here to keep track of what I was doing
### x <- 1:100
### y <- 30 + 10 * x
### newData_df <- data.frame(x = x, y = y, sd = 3.9)
### newData_summ <- newData_df %>%
### summarise(sd(x))
### newData_summ
# - - - - -
#### 1) First, define the regression model parameters (intercept, slope, error) (hint: just make variables called 'intercept' and so on and define the number)
newData_int <- 30
newData_slope <- 10
newData_err <- 3.9
#### 3) Generate X values in the specified range using seq()
x <- 1:100
#### 4) Calculate y values based on the given regression and your newly created x-values without the error term, which gives you the y get the perfect fit line
y <- 30 + 10 * x
#### 5) Add random error to the line we fit above: we can introduce variability by adding some normally distributed random errors to the y values. This can be done using rnorm() as in the 0-exercises, with mean 0 and standard deviation equal to the residual standard deviation (3.9) for instance.
newData <- rnorm(100, mean = 0, sd = 3.9)
#### 6) Prepare data for plotting: get the x-values and y-values in a dataframe to prepare for plotting w. ggplot
#### 7) Now, plot to check it out
#### 8) Optional: Fit and review a regression model: As an additional step, you can fit a linear regression model to the generated data using stan_glm() or any other fitting function to see how closely the estimated parameters match the ones used to generate the data.
# playing around with some things.. didn't work sooooo it's hashed out, but here to keep track of what I was doing
### x <- 1:100
### y <- 30 + 10 * x
### newData_df <- data.frame(x = x, y = y, sd = 3.9)
### newData_summ <- newData_df %>%
### summarise(sd(x))
### newData_summ
# - - - - -
#### 1) First, define the regression model parameters (intercept, slope, error) (hint: just make variables called 'intercept' and so on and define the number)
newData_int <- 30
newData_slope <- 10
newData_err <- 3.9
#### 3) Generate X values in the specified range using seq()
x <- 1:100
#### 4) Calculate y values based on the given regression and your newly created x-values without the error term, which gives you the y get the perfect fit line
y <- 30 + (10 * x)
#### 5) Add random error to the line we fit above: we can introduce variability by adding some normally distributed random errors to the y values. This can be done using rnorm() as in the 0-exercises, with mean 0 and standard deviation equal to the residual standard deviation (3.9) for instance.
newData <- rnorm(100, mean = 0, sd = 3.9)
#### 6) Prepare data for plotting: get the x-values and y-values in a dataframe to prepare for plotting w. ggplot
#### 7) Now, plot to check it out
#### 8) Optional: Fit and review a regression model: As an additional step, you can fit a linear regression model to the generated data using stan_glm() or any other fitting function to see how closely the estimated parameters match the ones used to generate the data.
newData_df <- data.frame(x = x, y = y)
# playing around with some things.. didn't work sooooo it's hashed out, but here to keep track of what I was doing
### x <- 1:100
### y <- 30 + 10 * x
### newData_df <- data.frame(x = x, y = y, sd = 3.9)
### newData_summ <- newData_df %>%
### summarise(sd(x))
### newData_summ
# - - - - -
#### 1) First, define the regression model parameters (intercept, slope, error) (hint: just make variables called 'intercept' and so on and define the number)
newData_int <- 30
newData_slope <- 10
newData_err <- 3.9
#### 3) Generate X values in the specified range using seq()
x <- 1:100
#### 4) Calculate y values based on the given regression and your newly created x-values without the error term, which gives you the y get the perfect fit line
y <- 30 + (10 * x)
#### 5) Add random error to the line we fit above: we can introduce variability by adding some normally distributed random errors to the y values. This can be done using rnorm() as in the 0-exercises, with mean 0 and standard deviation equal to the residual standard deviation (3.9) for instance.
newData <- rnorm(100, mean = 0, sd = 3.9)
#### 6) Prepare data for plotting: get the x-values and y-values in a dataframe to prepare for plotting w. ggplot
newData_df <- data.frame(x = x, y = y)
#### 7) Now, plot to check it out
newData_plot <- newData_df %>%
ggplot(aes(x = x, y = y)) +
geom_point() +
geom_smooth(method = "lm") +
labs(x = "x",
y = "y",
title = "newData Plot + Regression")
#### 8) Optional: Fit and review a regression model: As an additional step, you can fit a linear regression model to the generated data using stan_glm() or any other fitting function to see how closely the estimated parameters match the ones used to generate the data.
newData_plot
# playing around with some things.. didn't work sooooo it's hashed out, but here to keep track of what I was doing
### x <- 1:100
### y <- 30 + 10 * x
### newData_df <- data.frame(x = x, y = y, sd = 3.9)
### newData_summ <- newData_df %>%
### summarise(sd(x))
### newData_summ
# - - - - -
#### 1) First, define the regression model parameters (intercept, slope, error) (hint: just make variables called 'intercept' and so on and define the number)
newData_int <- 30
newData_slope <- 10
newData_err <- 3.9
#### 3) Generate X values in the specified range using seq()
x <- 1:100
#### 4) Calculate y values based on the given regression and your newly created x-values without the error term, which gives you the y get the perfect fit line
y <- 30 + (10 * x)
#### 5) Add random error to the line we fit above: we can introduce variability by adding some normally distributed random errors to the y values. This can be done using rnorm() as in the 0-exercises, with mean 0 and standard deviation equal to the residual standard deviation (3.9) for instance.
newData <- rnorm(100, mean = 0, sd = 3.9)
#### 6) Prepare data for plotting: get the x-values and y-values in a dataframe to prepare for plotting w. ggplot
newData_df <- data.frame(x = x, y = y)
#### 7) Now, plot to check it out
newData_plot <- newData_df %>%
ggplot(aes(x = x, y = y)) +
geom_point() +
geom_smooth(method = "lm", se = TRUE) +
labs(x = "x",
y = "y",
title = "newData Plot + Regression")
newData_plot
#### 8) Optional: Fit and review a regression model: As an additional step, you can fit a linear regression model to the generated data using stan_glm() or any other fitting function to see how closely the estimated parameters match the ones used to generate the data.
newData_plot <- newData_df %>%
ggplot(aes(x = x, y = y)) +
geom_point() +
geom_smooth(method = "lm", se = 3.9) +
labs(x = "x",
y = "y",
title = "newData Plot + Regression")
newData_plot
knitr::opts_chunk$set(echo = TRUE)
# Setting my root directory to where I have my /data folder etc. (easier for me, but personalise to your own way of working)
knitr::opts_knit$set(root.dir = "/Users/aisro/Desktop/UNI/BSc CogSci - 2nd Sem/Methods 2/github repos/methods2_resources/classes/data")
knitr::opts_chunk$set(echo = TRUE)
# Setting my root directory to where I have my /data folder etc. (easier for me, but personalise to your own way of working)
knitr::opts_knit$set(root.dir = "/Users/aisro/Desktop/UNI/BSc CogSci - 2nd Sem/Methods 2/github repos/methods2_resources/classes/data")
setwd("/Users/aisro/Desktop/UNI/BSc CogSci - 2nd Sem/Methods 2/github repos/methods2_resources/classes/data")
setwd("~/")
knitr::opts_chunk$set(echo = TRUE)
# Setting my root directory to where I have my /data folder etc. (easier for me, but personalise to your own way of working)
knitr::opts_knit$set(root.dir = "/Users/aisro/Desktop/UNI/BSc CogSci - 2nd Sem/Methods 2/github repos/methods2_resources/classes/data")
setwd("/Users/aisro/Desktop/UNI/BSc CogSci - 2nd Sem/Methods 2/github repos/methods2_resources/classes/data")
knitr::opts_chunk$set(echo = TRUE)
# Setting my root directory to where I have my /data folder etc. (easier for me, but personalise to your own way of working)
knitr::opts_knit$set(root.dir = "/Users/aisro/Desktop/UNI/BSc CogSci - 2nd Sem/Methods 2/github repos/methods2_resources/classes/data")
setwd("/Users/aisro/Desktop/UNI/BSc CogSci - 2nd Sem/Methods 2/github repos/methods2_resources/classes/data")
# Setting my root directory to where I have my /data folder etc. (easier for me, but personalise to your own way of working)
knitr::opts_knit$set(root.dir = "/Users/aisro/Desktop/UNI/BSc CogSci - 2nd Sem/Methods 2/github repos/methods2_resources/classes/data")
knitr::opts_chunk$set(echo = TRUE)
# Setting my root directory to where I have my /data folder etc. (easier for me, but personalise to your own way of working)
knitr::opts_knit$set(root.dir = "/Users/aisro/Desktop/UNI/BSc CogSci - 2nd Sem/Methods 2/github repos/methods2_resources/classes/data")
setwd("/Users/aisro/Desktop/UNI/BSc CogSci - 2nd Sem/Methods 2/github repos/methods2_resources/classes/data")
setwd("C:/Users/aisro/Desktop/UNI/BSc CogSci - 2nd Sem/Methods 2/github repos/methods2_resources/classes/data")
knitr::opts_chunk$set(echo = TRUE)
# Setting my root directory to where I have my /data folder etc. (easier for me, but personalise to your own way of working)
knitr::opts_knit$set(root.dir = "/Users/aisro/Desktop/UNI/BSc CogSci - 2nd Sem/Methods 2/github repos/methods2_resources/classes/data")
setwd("Names")
setwd("Names/data")
read_csv("allnames_clean.csv")
knitr::opts_chunk$set(echo = TRUE)
# Setting my root directory to where I have my /data folder etc. (easier for me, but personalise to your own way of working)
knitr::opts_knit$set(root.dir = "/Users/aisro/Desktop/UNI/BSc CogSci - 2nd Sem/Methods 2/github repos/methods2_resources/classes/data")
# Make sure this guy is installed/updated (if you've already got rstanarm installed, you just need to load it in using either library() or p_load() as below)
#install.packages("rstanarm")
#library(rstanarm)
#remove.packages("htmltools")
#packageVersion("htmltools") # do not look back. just move on. be happy it's there.
#install.packages("htmltools", version = "0.5.7")
#stan_glm(mpg ~ wt + cyl, data = mtcars) # testing line
# Load the rest
library(pacman)
pacman::p_load(tidyverse,
ggpubr,
ggplot2,
stringr,
rstanarm) # this time I'm just giving you the code
# Load data
hibbs <- read.table("ElectionsEconomy/data/hibbs.dat", header = TRUE)
# Make scatterplot
plot(hibbs$growth, hibbs$vote, xlab="Average recent growth in personal income",
ylab="Incumbent party's vote share")
# Estimate regression y = a + bx + error
M1 <- stan_glm(vote ~ growth, data=hibbs)
# Add a fitted line to the graph
abline(coef(M1), col="violet") # needs to be run with the plot() code above - running the whole chunk is the easiest way
# Display the fitted model
print(M1)
# Basic plot with ggplot2
ggplot(hibbs, aes(x = growth, y = vote)) +
geom_point() +  # Add points
labs(
x = "Average recent growth in personal income",
y = "Incumbent party's vote share",
title = "Relationship between Income Growth and Vote Share",
subtitle = "Data from Hibbs Dataset"
) +
theme_minimal() +  # Use a minimal theme
theme(
plot.title = element_text(hjust = 0.5),  # Center the title
plot.subtitle = element_text(hjust = 0.5)  # Center the subtitle
) +
geom_smooth(method = "lm", se = FALSE, color = "blue")  # Add a linear regression line
#set.seed(1998) # setting a seed (in the best year ever??) - this way, even though it's random, you'll get reproducible results next time you run this with this seed --- im sorry
set.seed(2005)
# rnorm() works like: my_simulated_data <- rnorm(n, mean, sd) - now you go!
# your code here
simData <- rnorm(2005,4.5,1)
simData_df <- data.frame(x = simData) # needs to be converted from vector to data frame
simData_histo <- simData_df %>%
ggplot(aes(x = x))+
geom_histogram(binwidth = 0.5, fill = "skyblue", color = "black")+ # creating a histogram :)
labs(x = "number",
y = "frequency",
title = "Simulated Data")
simData_histo # view
simData_summ <- simData_df %>%
summarise(mean(x),
sd(x))
simData_summ # mean = 4.50, sd = 0.98 --- could be rounded up to mean = 4.5, and sd = 1 -- which is basically the same but still not accurate. The difference in input vs actual could be attributed the inherent variability when selecting random values.
simData_summ <- simData_df %>%
summarise(mean(x),
sd(x))
simData_summ # mean = 4.50, sd = 0.98 --- could be rounded up to mean = 4.5, and sd = 1 -- which is basically the same but still not accurate. The difference in input vs actual could be attributed the inherent variability when selecting random values.
set.seed(607)
x <- 1:100 #IV (range)
y <- 2 * x + rnorm(100, mean = 39, sd = 3) #DV + noise
datData_df <- data.frame(x = x, y = y) # vector to df
datData_model <- lm(y ~ x, data = datData_df)
summary(datData_model)
datData_plot <- datData_df %>%
ggplot(aes(x = x, y = y)) +
geom_point() +
geom_smooth(method = "lm") +
labs(x = "x",
y = "y",
title = "datData Scatter Plot w/ Regression Line")
datData_plot
# playing around with some things.. didn't work sooooo it's hashed out, but here to keep track of what I was doing
### x <- 1:100
### y <- 30 + 10 * x
### newData_df <- data.frame(x = x, y = y, sd = 3.9)
### newData_summ <- newData_df %>%
### summarise(sd(x))
### newData_summ
# - - - - -
#### 1) First, define the regression model parameters (intercept, slope, error) (hint: just make variables called 'intercept' and so on and define the number)
newData_int <- 30
newData_slope <- 10
newData_err <- 3.9
#### 3) Generate X values in the specified range using seq()
x <- 1:100
#### 4) Calculate y values based on the given regression and your newly created x-values without the error term, which gives you the y get the perfect fit line
y <- 30 + (10 * x)
#### 5) Add random error to the line we fit above: we can introduce variability by adding some normally distributed random errors to the y values. This can be done using rnorm() as in the 0-exercises, with mean 0 and standard deviation equal to the residual standard deviation (3.9) for instance.
newData <- rnorm(100, mean = 0, sd = 3.9)
#### 6) Prepare data for plotting: get the x-values and y-values in a dataframe to prepare for plotting w. ggplot
newData_df <- data.frame(x = x, y = y)
#### 7) Now, plot to check it out
newData_plot <- newData_df %>%
ggplot(aes(x = x, y = y)) +
geom_point() +
geom_smooth(method = "lm", se = 3.9) + #hmmmmmm something has gone wrong here..
labs(x = "x",
y = "y",
title = "newData Plot + Regression")
newData_plot
#### 8) Optional: Fit and review a regression model: As an additional step, you can fit a linear regression model to the generated data using stan_glm() or any other fitting function to see how closely the estimated parameters match the ones used to generate the data.
setwd("Names/data")
read_csv("allnames_clean.csv")
allNames_df <- read_csv("allnames_clean.csv")
setwd("Names/data")
allNames_df <- read_csv("allnames_clean.csv")
girlNames_plot <-
head(allNames_df)
# prepping the data f/ analysis
girlNames_df <- allNames_df %>%
select(sex = "F")
head(allNames_df)
# prepping the data f/ analysis
girlNames_df <- allNames_df %>%
filter(sex = "F")
# prepping the data f/ analysis
girlNames_df <- allNames_df %>%
filter(sex == "F")
View(girlNames_df)
?gather
?pivot_longer
head(allNames_df)
yearNames_df <- allNames_df %>%
c(4:134)
View(yearNames_df)
yearNames_data <- allNames_df %>%
c(4:134)
head(allNames_df)
# prepping the data f/ analysis
girlNames_df <- allNames_df %>%
filter(sex == "F") %>%
filter(substr(name, nchar(name), nchar(name)) == "n") %>%
group_by(yearNames_data) %>%
summarise(nNames_data = sum(count))
yearNames_data <- allNames_df %>%
c(4:134)
# prepping the data f/ analysis
girlNames_df <- allNames_df %>%
filter(sex == "F") %>%
filter(substr(name, nchar(name), nchar(name)) == "n") %>%
group_by(yearNames_data) %>%
summarise(nNames_data = sum(count))
setwd("Names/data")
allNames_df <- read_csv("allnames_clean.csv")
head(allNames_df)
yearNames_data <- allNames_df %>%
c(4:134)
# prepping the data f/ analysis
girlNames_df <- allNames_df %>%
filter(sex == "F") %>%
filter(substr(name, nchar(name), nchar(name)) == "n") %>%
group_by(yearNames_data) %>%
summarise(nNames_data = sum(count))
yearNames_df <- data.frame(yearNames_data)
# prepping the data f/ analysis
girlNames_df <- allNames_df %>%
filter(sex == "F") %>%
filter(substr(name, nchar(name), nchar(name)) == "n") %>%
group_by(yearNames_data) %>%
summarise(nNames_data = sum(count))
# prepping the data f/ analysis
girlNames_df <- allNames_df %>%
filter(sex == "F") %>%
filter(substr(name, nchar(name), nchar(name)) == "n") %>%
group_by(yearNames_df) %>%
summarise(nNames_data = sum(count))
?gather
yearNames_long <- gather(yearNames_df, key = "X", value = "value")
View(yearNames_long)
